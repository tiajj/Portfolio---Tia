
---
title: "Rock Through The Ages"
output: 
  flexdashboard::flex_dashboard:

---

 How does rock music change over the years? {.storyboard}
=========================================
```{r}
``` 

The corpus I chose to be represented in my final assignment is a comparison of rock music from the 80s, 90s and 2000s. The rock genre is my favourite across the decades and looking into what ties them together and sets them apart is interesting to me. The natural comparison point in this corpus would be the genre, separated by the decade, specifically the 80s, 90s, and early 2000s. 

Through this corpus, I expect the themes between decades to be quite similar, as no matter the year, the rock genre stands for certain messages that won't change, such as themes of rebellion, social commentary, and personal struggles across all three decades. However, I expect the musical style to differ between the decades, making the 90s have more energy than the 80s, and the 2000s even more than the 90s. 

Overall, I don't see any limitations or gaps in the chosen corpus. If I were to potentially expand it, I would expect gaps in lesser known artists, or covers of known songs, but in the already selected corpus with limited tracks, I didn't face any obstacles with gaps in Spotify.

Some typical tracks from my corpus include "Sweet Child o' Mine" by Guns N' Roses, "Smells Like Teen Spirit" by Nirvana, or "How You Remind Me" by Nickelback, as these are considered to be perfect representation of the genre at the stage of their decade. On the other hand, some atypical tracks would be "Wonderwall" by Oasis or "Feel Good Inc." by Gorillaz seeing as these are tracks that deviate from the mainstream trends and offer a more unique or experimental approach to the genre.

Under the hood of some of the world's most famous chords {.storyboard}
=========================================

```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(ggplot2)
library(dplyr)
library(conflicted)
library(forcats)
library(lubridate)
library(purrr)
library(readr)
library(stringr)
library(tibble)
library(tidyr)
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

```

```{r,echo=FALSE, fig.width=10, fig.height=7}
get_tidy_audio_analysis("37ZJ0p5Jm13JPevGcx4SkF?si=9e905a922153474b")

livingonaprayer <-
  get_tidy_audio_analysis("37ZJ0p5Jm13JPevGcx4SkF?si=9e905a922153474b") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
livingonaprayer |> 
  compmus_match_pitch_template(
    chord_templates,         
    method = "euclidean",  
    norm = "manhattan"     
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")

```

***
"Livin' On A Prayer" by Bon Jovi is not only one of the most famous songs the band has made, but it is one of the most famous songs of all time. It features a distinctive chord progression that is both recognizable and iconic in the realm of rock music. 


Keys as beautiful as a soft November Rain {.storyboard}
=========================================

```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(ggplot2)
library(dplyr)
library(conflicted)
library(forcats)
library(lubridate)
library(purrr)
library(readr)
library(stringr)
library(tibble)
library(tidyr)
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
novemberrain <-
  get_tidy_audio_analysis("3YRCqOhFifThpSRFJ1VWFM?si=fba96e4ef0d94883") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
novemberrain |> 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",  
    norm = "manhattan"     
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

***
"November Rain" by Guns'N'Roses is a song who's keys are so distinct they can be indetified anywhere, anytime, by anyone. "Novemeber Rain" incorporates various key changes and modulations throughout the song, and analyzing the key changes in a keygram can reveal the song's overall tonal journey, highlighting key moments and transitions that contribute to its emotional impact.

 Deciphering the Keys to the Decades {.storyboard}
=========================================

```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(ggplot2)
library(dplyr)
library(conflicted)
library(forcats)
library(lubridate)
library(purrr)
library(readr)
library(stringr)
library(tibble)
library(tidyr)
library(hrbrthemes)
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
eightys <- get_playlist_audio_features("", "7wFHQHyooUBgtrPqW3iGzk?si=324313907b804876")
ninetys <- get_playlist_audio_features("", "1CkbyHSuvnAXdosoBW6Vm0?si=9814498c432f487e")
twothousands <- get_playlist_audio_features("", "7IeVftpjOptptIDThtx3rd?si=833a8a98a01e48f2")

corpus <-
  bind_rows(
    eightys |> mutate(category = "80s"),
    ninetys |> mutate(category = "90s"),
    twothousands |> mutate(category = "00s")
  )
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
corpus %>%
  ggplot(aes(x = key_name, fill = category)) +
  geom_bar(stat = "count", position = "dodge") +  
  labs(title = "Histogram of Keys by Decade", x = "Key", y = "Frequency") +
  scale_fill_manual(values = c("Group A" = "blue", "Group B" = "red", "Group C" = "green")) +
  facet_wrap(~category, scales = "free") 
```

***
Using this visualisation, we can see the most popular keys used in each decade of rock music. An interesting takeway from this is while they stay similar throughout the decade, there are slight differences we can spot.

Tempo throught the Times {.storyboard}
=========================================

```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(ggplot2)
library(dplyr)
library(conflicted)
library(forcats)
library(lubridate)
library(purrr)
library(readr)
library(stringr)
library(tibble)
library(tidyr)
library(hrbrthemes)
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
eightys <-
  get_playlist_audio_features(
    "",
    "7wFHQHyooUBgtrPqW3iGzk?si=b182e4f2d7b7444c"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
ninetys <-
  get_playlist_audio_features(
    "",
    "1CkbyHSuvnAXdosoBW6Vm0?si=a25d611128c54f8c"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
twothousands <-
  get_playlist_audio_features(
    "",
    "7IeVftpjOptptIDThtx3rd?si=0ae8238ab6c148fc"
  ) |>
  slice(1:30) |>
  add_audio_analysis()

corpus <- eightys %>%
  mutate(genre = "Eighties") %>%
  bind_rows(ninetys %>% mutate(genre = "Nineties")) %>%
  bind_rows(twothousands %>% mutate(genre = "Two Thousands"))
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
corpus |>
  mutate(
    sections =
      map(
        sections,                                    
        summarise_at,
        vars(tempo, loudness, duration),             
        list(section_mean = mean, section_sd = sd)   
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

***

With this visualisation, we can compare the songs in the corpus from all three decades in regards to their tempo. 


 The American Idiot shines as bright as a star {.storyboard}
=========================================

```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(ggplot2)
library(dplyr)
library(conflicted)
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
get_tidy_audio_analysis("6nTiIhLmQ3FWhvrGafw2zj?si=e0fdcac6a10e48c4")


americanidiot <-
  get_tidy_audio_analysis("6nTiIhLmQ3FWhvrGafw2zj?si=e0fdcac6a10e48c4") |> 
  compmus_align(beats, segments) |>                     
  select(beats) |>                                      
  unnest(beats) |>                                      
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"             
      )
  )
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
americanidiot |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()

```

***
Spotify's API looks into multiple variables to analyse their tracks. When looking into what an important outlier would be to visualize as a cepstrogram, two variables stood out: loudness and energy. It just so happens that one sing in my corpus was both the loudest and had the most energy, and that was "American Idiot" by Greenday.This can be visually seen through the cepstrogram by how high the magnitude is in c01, but mainly in c02, throughout the whole songs.

Visualizing the Beat: Exploring Typical vs. Atypical 90s rock {.storyboard}
=========================================

### Wonderwall by Oasis: Self Similarity Matrix based on Timbre

```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(dplyr)
library(ggplot2)
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
get_tidy_audio_analysis("7ygpwy2qP3NbrxVkHvUhXY?si=3e98096edbf84a7a")



wonderwall <-
  get_tidy_audio_analysis("7ygpwy2qP3NbrxVkHvUhXY?si=3e98096edbf84a7a") |> 
  compmus_align(beats, segments) |>                     
  select(beats) |>                                      
  unnest(beats) |>                                      
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"             
      )
  )
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
wonderwall |>
  compmus_self_similarity(timbre, "euclidean") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```


***
When introducing my corpus, I detailed what may be considered typical and atypical songs from each decade. From the 90s, what can be considered an atypical song of the rock genre would be "Wonderwall" by Oasis. Here, you can see the self similarity matrix based on timbre for the song mentioned. You can see an obvious point of comparison just after the 100 second mark. When listening to the song, this is a point right after the chorus. I believe this stands out when looking at timbre features is because of the isolation of instruments in this segments. You can clearly separate the drums, guitar, and vocals here.

### Wonderwall by Oasis: Self Similarity Matrix based on Chroma
```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(dplyr)
library(ggplot2)
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
get_tidy_audio_analysis("7ygpwy2qP3NbrxVkHvUhXY?si=3e98096edbf84a7a")



wonderwall <-
  get_tidy_audio_analysis("7ygpwy2qP3NbrxVkHvUhXY?si=3e98096edbf84a7a") |> 
  compmus_align(beats, segments) |>                     
  select(beats) |>                                      
  unnest(beats) |>                                      
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"             
      )
  )
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
wonderwall |>
  compmus_self_similarity(pitches, "euclidean") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```


***
Similarly, when looking at the chroma features through a self similarity matrix, this point of comparison also stands out due to the similarities of the pitches.

### Smells Like Teen Spirit by Nirvana: Self Similarity Matrix based on Timbre

```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(dplyr)
library(ggplot2)
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
get_tidy_audio_analysis("4CeeEOM32jQcH3eN9Q2dGj?si=d7d6bf42c9504ab0")



teenspirit <-
  get_tidy_audio_analysis("4CeeEOM32jQcH3eN9Q2dGj?si=d7d6bf42c9504ab0") |> 
  compmus_align(beats, segments) |>                     
  select(beats) |>                                      
  unnest(beats) |>                                      
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"             
      )
  )
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
teenspirit |>
  compmus_self_similarity(timbre, "euclidean") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```


***
We discussed what an atypical rock song form the 90s looks like, what about a typical one? For example "Smells Like Teen Spirit" by Nirvana. When looking at the self similarity matrix based on timbre features of the song. You can see the darkest part of the grid is between almost the 160 second mark and the 210 second mark. This is because there is an instrumental section where the instruments clearly stand out and you can dustinguish the differen instruments playing in this segment. On the other hand, when you compare this segment to the one from roughly 25 seconds to 60 seconds, you can see that it is yellow and quite light colored on the matrix, meaning there is little similarity between both segments. If you listen to this passage in the song, it was quite low energy compared the instrument solo later on, which explains the light colors on the matrix.

### Smells Like Teen Spirit by Nirvana: Self Similarity Matrix based on Chroma 
```{r,echo=FALSE, fig.width=10, fig.height=7}
library(tidyverse)
library(spotifyr)
library(compmus)
library(dplyr)
library(ggplot2)
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
get_tidy_audio_analysis("4CeeEOM32jQcH3eN9Q2dGj?si=d7d6bf42c9504ab0")



teenspirit <-
  get_tidy_audio_analysis("4CeeEOM32jQcH3eN9Q2dGj?si=d7d6bf42c9504ab0") |> 
  compmus_align(beats, segments) |>                     
  select(beats) |>                                      
  unnest(beats) |>                                      
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"             
      )
  )
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
teenspirit |>
  compmus_self_similarity(pitches, "euclidean") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

```


***

When looking at the same song's self similarity matrix but based on chroma features this time, you see that more or less, the same passages light up, however the colored "squares" are vary more in this matrix and that's because instead of just comparing the "feel" of the segment, it compares he specific pitch, also known as chroma.

### What can we conclude

```{r}
``` 

What we can take away from the analysis of both of these songs, is that it is much easier to look into the differences and similarities of the timbre and chroma of a typical song from the rock genre. When looking at the visualisations of "Smells Like Teen Spirit" by Nirvana, there are certain aspects that stand out to the eye and make it quite easy to analyse. On the other hand, when looking at the visualisations of "Wonderwall" by Oasis, it is much more difficult to find moments that stand out. 
In my opinion, this is because in the typical song, there is a variation of timbre and chroma, the segments range from high energy and loundness to low energy. In the atypical song, the chroma and pitch of the segments is more or less the same throughout the song, and the same goes for timbre.


00s kids likely to go lose hearing in their younger years {.storyboard}
=========================================
```{r, echo=FALSE, fig.width=10, fig.height=7}

library(ggplot2)
library(dplyr)
library(spotifyr)
library(tidyverse)
library(compmus)
library(conflicted)
```
```{r}

eightys <- get_playlist_audio_features("", "7wFHQHyooUBgtrPqW3iGzk?si=324313907b804876")
ninetys <- get_playlist_audio_features("", "1CkbyHSuvnAXdosoBW6Vm0?si=9814498c432f487e")
twothousands <- get_playlist_audio_features("", "7IeVftpjOptptIDThtx3rd?si=833a8a98a01e48f2")

corpus <-
  bind_rows(
    eightys |> mutate(category = "80s"),
    ninetys |> mutate(category = "90s"),
    twothousands |> mutate(category = "00s")
)
```
```{r,echo=FALSE, fig.width=10, fig.height=7}
corpus |>                   
  mutate(
    track.popularity = ifelse(track.popularity < 75, "Little", "Very")
  ) |>
  ggplot(                   
    aes(
      x = valence,
      y = danceability,
      size = loudness,
      colour = track.popularity
    )
  ) +
  geom_point() +              
  geom_rug(linewidth = 0.1) +  
  geom_text(                 
    aes(
      x = valence,
      y = danceability,
      label = label
    ),
    data = 
      tibble(
        label = c("Shadow of the Day", "Girl, You'll be a Woman Soon", "I Love Rock 'N Rol"),
        category = c("00s", "90s", "80s"),
        valence = c(0.0641, 0.5570, 0.9010),
        danceability = c(0.534, 0.514, 0.535)
      ),
    colour = "black",        
    size = 3,                 
    hjust = "left",           
    vjust = "center",         
    nudge_x = 0.02            
  ) +
  facet_wrap(~ category) +    
  scale_x_continuous(         
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),   
    minor_breaks = NULL       
  ) +
  scale_y_continuous(         
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(        
    type = "qual",            
    palette = "Paired"        
  ) +
  scale_size_continuous(      
    trans = "exp",            
    guide = "none"            
  ) +
  theme_light() +             
  labs(                       
    x = "Valence",
    y = "Danceability",
    colour = "Popularity"
  )
```

  
***
The scatter plot I made is divided into three sections, one for each decade, with the Danceability variable on the y-axis and the Valence variable on te x-axis. I was interested to see if the valence of a song made it more danceable. Other variables measured in this scatter plot are Track Popularity, measured by color, where a track is considered "Very" popular if it measured superior to 75, and "Little" popular if it measured inferior to 75. I also measured loudness, which I found interesting to look into for rock music, and that variable is measured by size. From the plot, I can see that 00s rock is louder than both other decades, which was interesting to find out, but not surprising. Valence and Dancebaility don't affect track popularity, and if valence and dasnecability have an effect on one another, it can't be seen from a quick visualisation and would need to be looked into further.

 A Happier Time {.storyboard}
=========================================
```{r,echo=FALSE, fig.width=10, fig.height=7}

library(ggplot2)
library(dplyr)
library(spotifyr)
library(tidyverse)
library(compmus)
library(conflicted)
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
get_tidy_audio_analysis("2Cdvbe2G4hZsnhNMKyGrie?si=ea353a7b64f24f6e")

rocknroll <-
  get_tidy_audio_analysis("2Cdvbe2G4hZsnhNMKyGrie?si=ea353a7b64f24f6e") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
```

```{r,echo=FALSE, fig.width=10, fig.height=7}
rocknroll |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```
  

*** 
Out of 90 songs through 3 decade, this song, "I Love Rock 'N Roll" by Joan Jett & the Blackhearts, had the most valence. If you really focus, the 80s generally had happier rock music than the other two decades we're looking into. So, the happied rock song of the 80s, 90s, and the 00s, is no presented as a chromogram.
